"""
4ê°€ì§€ ì„ë² ë”© ëª¨ë¸ ë¹„êµ: jina-v2, snowflake-arctic, gte-multilingual, e5-large
ê° ëª¨ë¸ë¡œ Vector DBë¥¼ ìƒì„±í•˜ê³  ê²€ìƒ‰ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
"""

import os
import sys
import time
import json
from dotenv import load_dotenv
import chromadb
from tqdm import tqdm

# Disable TensorFlow to avoid Keras compatibility issues
os.environ['USE_TF'] = '0'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass

from embedding_models import get_embedding_model
from ad_message_generator import AdMessageGenerator

load_dotenv()


class ModelComparison:
    """4ê°€ì§€ ëª¨ë¸ ë¹„êµ í´ë˜ìŠ¤"""

    def __init__(self):
        self.models = ["jina-v2", "snowflake-arctic", "gte-multilingual", "e5-large"]
        self.results = {}
        # 3ê°œì˜ JSONL íŒŒì¼ ëª¨ë‘ ì‚¬ìš©
        self.jsonl_files = [
            r"C:\Users\82104\Desktop\vscode\AI-INNOVATION-CHALLENGE-2026-son_branch\data\crawling_result\product_crawling_2512060138.jsonl",
            r"C:\Users\82104\Desktop\vscode\AI-INNOVATION-CHALLENGE-2026-son_branch\data\crawling_result\product_crawling_2512060343.jsonl",
            r"C:\Users\82104\Desktop\vscode\AI-INNOVATION-CHALLENGE-2026-son_branch\data\crawling_result\product_crawling_2512081458.jsonl"
        ]

    def create_vectordb(self, model_name: str):
        """íŠ¹ì • ëª¨ë¸ë¡œ Vector DB ìƒì„±"""
        print(f"\n{'='*80}")
        print(f"ğŸ”§ [{model_name.upper()}] Vector DB ìƒì„± ì¤‘...")
        print(f"{'='*80}")

        # ëª¨ë¸ ë¡œë”©
        start_time = time.time()
        embedder = get_embedding_model(model_name)
        load_time = time.time() - start_time

        print(f"âœ… ëª¨ë¸: {embedder.get_name()}")
        print(f"   ì°¨ì›: {embedder.get_dimension()}")
        print(f"   ë¡œë”© ì‹œê°„: {load_time:.2f}ì´ˆ")

        # Chroma DB (ëª¨ë¸ë³„ ê²½ë¡œ)
        db_path = f"./chroma_db_{model_name}"
        client = chromadb.PersistentClient(path=db_path)

        try:
            client.delete_collection("products")
        except:
            pass

        collection = client.create_collection(
            name="products",
            metadata={"description": f"ìƒí’ˆ ({model_name})"}
        )

        # ë°ì´í„° ë¡œë“œ (3ê°œ íŒŒì¼ ëª¨ë‘ ì½ê¸°)
        products = []
        for jsonl_file in self.jsonl_files:
            if not os.path.exists(jsonl_file):
                print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_file}")
                continue

            with open(jsonl_file, 'r', encoding='utf-8') as f:
                file_products = 0
                for line in f:
                    if line.strip():
                        try:
                            product = json.loads(line)
                            if product is not None:  # None ì²´í¬
                                products.append(product)
                                file_products += 1
                        except json.JSONDecodeError:
                            continue  # ì˜ëª»ëœ JSON ë¼ì¸ ê±´ë„ˆë›°ê¸°
                print(f"   âœ“ {os.path.basename(jsonl_file)}: {file_products}ê°œ ìƒí’ˆ")

        print(f"ğŸ“¦ ì´ {len(products)}ê°œ ìƒí’ˆ (3ê°œ íŒŒì¼ í†µí•©)")

        # ì„ë² ë”© ìƒì„±
        embed_start = time.time()
        ids, embeddings, documents, metadatas = [], [], [], []

        for idx, product in enumerate(tqdm(products, desc=f"{model_name} ì„ë² ë”©")):
            try:
                # None ì²´í¬
                if product is None:
                    continue

                # ê°€ê²© íŒŒì‹± (ì´ë¯¸ int)
                price = product.get('íŒë§¤ê°€', 0)
                original_price = product.get('ì›ê°€', 0)

                # ë³„ì  íŒŒì‹± (null ì²˜ë¦¬)
                rating = product.get('ë³„ì ', 0)
                rating = 0.0 if rating is None else float(rating)

                # ë¦¬ë·° ê°œìˆ˜
                review_count = product.get('ë¦¬ë·°_ê°¯ìˆ˜', 0) or 0

                # í• ì¸ìœ¨
                discount = product.get('í• ì¸ìœ¨', 0)

                # êµ¬ë§¤ì í†µê³„ (None ì²´í¬)
                buyer_stats = product.get('êµ¬ë§¤ì_í†µê³„') or {}
                skin_type_stats = buyer_stats.get('í”¼ë¶€íƒ€ì…ë³„', {})
                age_stats = buyer_stats.get('ì—°ë ¹ëŒ€ë³„', {})

                # ì„ë² ë”© í…ìŠ¤íŠ¸ (ë” ìƒì„¸í•˜ê²Œ)
                text = f"""
ë¸Œëœë“œ: {product.get('ë¸Œëœë“œ', 'N/A')}
ìƒí’ˆëª…: {product.get('ìƒí’ˆëª…', 'N/A')}
ì›ê°€: â‚©{original_price:,}
í• ì¸ìœ¨: {discount}%
íŒë§¤ê°€: â‚©{price:,}
ë³„ì : {rating}/5.0
ë¦¬ë·°: {review_count}ê°œ
í”¼ë¶€íƒ€ì…ë³„ êµ¬ë§¤ë¹„ìœ¨: {', '.join([f'{k}: {v}%' for k, v in skin_type_stats.items()]) if skin_type_stats else 'N/A'}
ì—°ë ¹ëŒ€ë³„ êµ¬ë§¤ë¹„ìœ¨: {', '.join([f'{k}: {v}%' for k, v in age_stats.items()]) if age_stats else 'N/A'}
                """.strip()

                embedding = embedder.embed(text)

                if embedding:
                    ids.append(f"product_{idx}")
                    embeddings.append(embedding)
                    documents.append(text)
                    metadatas.append({
                        "brand": product.get('ë¸Œëœë“œ', 'N/A'),
                        "product_name": product.get('ìƒí’ˆëª…', 'N/A'),
                        "price": int(price),
                        "discount_rate": str(discount) + '%',
                        "rating": rating,
                        "review_count": int(review_count),
                        "url": product.get('url', ''),
                    })

            except Exception as e:
                print(f"âš ï¸ ì˜¤ë¥˜ (ìƒí’ˆ {idx}): {e}")
                continue

        # ë°°ì¹˜ ì €ì¥
        batch_size = 100
        for i in range(0, len(ids), batch_size):
            collection.add(
                ids=ids[i:i+batch_size],
                embeddings=embeddings[i:i+batch_size],
                documents=documents[i:i+batch_size],
                metadatas=metadatas[i:i+batch_size]
            )

        embed_time = time.time() - embed_start

        print(f"âœ… ì„ë² ë”© ì™„ë£Œ: {len(ids)}ê°œ")
        print(f"   ì‹œê°„: {embed_time:.2f}ì´ˆ ({len(ids)/embed_time:.2f}ê°œ/ì´ˆ)")

        self.results[model_name] = {
            "load_time": load_time,
            "embed_time": embed_time,
            "total": len(ids),
            "speed": len(ids) / embed_time,
            "dimension": embedder.get_dimension(),
            "collection": collection,
            "embedder": embedder
        }

        return collection, embedder

    def test_search(self, model_name: str):
        """ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ” [{model_name.upper()}] ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")

        collection = self.results[model_name]["collection"]
        embedder = self.results[model_name]["embedder"]

        queries = [
            "ì£¼ë¦„ ê°œì„  ì•ˆí‹°ì—ì´ì§• í¬ë¦¼",
            "ë³´ìŠµ ìˆ˜ë¶„ í¬ë¦¼",
            "ë¯¼ê°ì„± í”¼ë¶€ ì§„ì •",
            "ë©”ì´í¬ì—… ë² ì´ìŠ¤",
            "ì•„ì´ì„€ë„ìš° íŒ”ë ˆíŠ¸"
        ]

        search_times = []
        results_list = []

        for query in queries:
            start = time.time()
            q_emb = embedder.embed(query)
            res = collection.query(query_embeddings=[q_emb], n_results=3)
            search_time = time.time() - start
            search_times.append(search_time)

            if res['metadatas'] and len(res['metadatas'][0]) > 0:
                top1 = res['metadatas'][0][0]
                results_list.append({
                    "query": query,
                    "top1_product": top1['product_name'],
                    "brand": top1['brand']
                })
                print(f"   '{query}' â†’ {top1['brand']} - {top1['product_name']} ({search_time*1000:.1f}ms)")

        avg_search = sum(search_times) / len(search_times)
        self.results[model_name]["avg_search"] = avg_search
        self.results[model_name]["search_results"] = results_list

        print(f"   í‰ê·  ê²€ìƒ‰: {avg_search*1000:.2f}ms")

    def test_ad_generation(self, model_name: str):
        """ì‹¤ì œ ê´‘ê³  ë©”ì‹œì§€ ìƒì„± í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“ [{model_name.upper()}] ê´‘ê³  ë©”ì‹œì§€ ìƒì„± í…ŒìŠ¤íŠ¸")

        collection = self.results[model_name]["collection"]
        embedder = self.results[model_name]["embedder"]

        # í…ŒìŠ¤íŠ¸ìš© í˜ë¥´ì†Œë‚˜ ì„ íƒ (40ëŒ€ ì•ˆí‹°ì—ì´ì§•)
        persona_id = "premium_antiaging_40s"

        # ë¸Œëœë“œ ì„ íƒ (ì´ë‹ˆìŠ¤í”„ë¦¬ë¡œ í…ŒìŠ¤íŠ¸)
        brand_name = "ì´ë‹ˆìŠ¤í”„ë¦¬"
        campaign_goal = "ì‹ ê·œ ê³ ê° í™•ë³´"

        # ê´‘ê³  ë©”ì‹œì§€ ìƒì„±
        try:
            # í˜„ì¬ ëª¨ë¸ì˜ ì»¬ë ‰ì…˜ê³¼ ì„ë² ë”ë¥¼ ì£¼ì…
            generator = AdMessageGenerator(
                products_collection=collection,
                embedder=embedder
            )

            start_time = time.time()
            result = generator.generate(
                brand=brand_name,
                persona_id=persona_id,
                campaign_goal=campaign_goal
            )
            gen_time = time.time() - start_time

            if result.variations and len(result.variations) > 0:
                # ì²« ë²ˆì§¸ ë°°ë¦¬ì—ì´ì…˜ë§Œ ì €ì¥
                first_var = result.variations[0]
                print(f"\n   ìƒì„± ì‹œê°„: {gen_time:.2f}ì´ˆ")
                print(f"   ì „ëµ: {first_var.strategy}")
                print(f"   ì œëª©: {first_var.subject}")
                print(f"   ë³¸ë¬¸ ê¸¸ì´: {len(first_var.body)}ì")
                print(f"   ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {first_var.body[:100]}...")

                self.results[model_name]["ad_generation"] = {
                    "generation_time": gen_time,
                    "message": {
                        "strategy": first_var.strategy,
                        "subject": first_var.subject,
                        "body": first_var.body
                    },
                    "products_used": [p['product_name'] for p in result.recommended_products[:3]]
                }
            else:
                print(f"   âš ï¸ ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨")
                self.results[model_name]["ad_generation"] = None

        except Exception as e:
            print(f"   âŒ ê´‘ê³  ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            self.results[model_name]["ad_generation"] = None

    def run(self):
        """ì „ì²´ ë¹„êµ ì‹¤í–‰"""
        print("\n" + "="*80)
        print("ğŸš€ 4ê°€ì§€ ì„ë² ë”© ëª¨ë¸ ë¹„êµ")
        print("   ëª¨ë¸: jina-v2, snowflake-arctic, gte-multilingual, e5-large")
        print("="*80)

        for model in self.models:
            try:
                self.create_vectordb(model)
                self.test_search(model)
                self.test_ad_generation(model)  # ê´‘ê³  ë©”ì‹œì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì¶”ê°€
            except Exception as e:
                print(f"âŒ {model} ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()

        self.print_summary()

    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½"""
        print("\n" + "="*80)
        print("ğŸ“Š ë¹„êµ ê²°ê³¼ ìš”ì•½")
        print("="*80)

        print("\n1ï¸âƒ£ ëª¨ë¸ ë¡œë”© ì‹œê°„")
        print("-" * 60)
        for m, r in self.results.items():
            print(f"   {m:12s}: {r['load_time']:6.2f}ì´ˆ")

        print("\n2ï¸âƒ£ ì„ë² ë”© ìƒì„± ì‹œê°„")
        print("-" * 60)
        for m, r in self.results.items():
            print(f"   {m:12s}: {r['embed_time']:6.2f}ì´ˆ ({r['speed']:.1f}ê°œ/ì´ˆ)")

        print("\n3ï¸âƒ£ ê²€ìƒ‰ ì†ë„")
        print("-" * 60)
        for m, r in self.results.items():
            if "avg_search" in r:
                print(f"   {m:12s}: {r['avg_search']*1000:6.2f}ms")

        print("\n4ï¸âƒ£ ì„ë² ë”© ì°¨ì›")
        print("-" * 60)
        for m, r in self.results.items():
            print(f"   {m:12s}: {r['dimension']}ì°¨ì›")

        print("\n5ï¸âƒ£ ê´‘ê³  ë©”ì‹œì§€ ìƒì„± ê²°ê³¼")
        print("-" * 60)
        for m, r in self.results.items():
            if "ad_generation" in r and r["ad_generation"]:
                ad = r["ad_generation"]
                print(f"\n   [{m.upper()}]")
                print(f"   ìƒì„± ì‹œê°„: {ad['generation_time']:.2f}ì´ˆ")
                print(f"   ì œëª©: {ad['message']['subject']}")
                print(f"   ë³¸ë¬¸ ê¸¸ì´: {len(ad['message']['body'])}ì")
                print(f"   ì‚¬ìš© ìƒí’ˆ: {', '.join(ad['products_used'])}")
                print(f"   ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {ad['message']['body'][:120]}...")
            else:
                print(f"   {m:12s}: ìƒì„± ì‹¤íŒ¨")

        # ìˆœìœ„
        print("\n" + "="*80)
        print("ğŸ† ì„±ëŠ¥ ìˆœìœ„")
        print("="*80)

        sorted_embed = sorted(self.results.items(), key=lambda x: x[1]['embed_time'])
        print("\nâš¡ ì„ë² ë”© ì†ë„ (ë¹ ë¥¸ ìˆœ):")
        for rank, (m, r) in enumerate(sorted_embed, 1):
            print(f"   {rank}. {m:12s}: {r['embed_time']:.2f}ì´ˆ")

        sorted_search = sorted(
            [(k, v) for k, v in self.results.items() if "avg_search" in v],
            key=lambda x: x[1]['avg_search']
        )
        print("\nğŸ” ê²€ìƒ‰ ì†ë„ (ë¹ ë¥¸ ìˆœ):")
        for rank, (m, r) in enumerate(sorted_search, 1):
            print(f"   {rank}. {m:12s}: {r['avg_search']*1000:.2f}ms")

        # ì¶”ì²œ
        print("\n" + "="*80)
        print("ğŸ’¡ ì¶”ì²œ")
        print("="*80)
        fastest = sorted_embed[0][0]
        print(f"\nâš¡ ê°€ì¥ ë¹ ë¦„: {fastest}")
        print(f"   ì†ë„: {self.results[fastest]['embed_time']:.2f}ì´ˆ")
        print(f"   ì°¨ì›: {self.results[fastest]['dimension']}")

        # JSON ì €ì¥
        output = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "models": {}
        }
        for m, r in self.results.items():
            output["models"][m] = {
                "load_time": r["load_time"],
                "embed_time": r["embed_time"],
                "total": r["total"],
                "speed": r["speed"],
                "dimension": r["dimension"],
                "avg_search": r.get("avg_search", 0),
                "search_results": r.get("search_results", []),
                "ad_generation": r.get("ad_generation", None)
            }

        filename = f"model_comparison_{time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {filename}")


if __name__ == "__main__":
    comparison = ModelComparison()
    comparison.run()
