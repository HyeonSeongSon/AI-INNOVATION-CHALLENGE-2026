import os
import json
from typing import List, Tuple
from models.persona import PersonaInput, CategoryResult
import openai 
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class CategoryMatcher:
    def __init__(self):
        # íŒ€ì›ê³¼ í•©ì˜ëœ ê³µí†µ ì¹´í…Œê³ ë¦¬ ì½”ë“œ
        self.CATEGORY_MAP = {
            "MOISTURE": ["ê±´ì„±", "ì†ê±´ì¡°", "ë‹¹ê¹€", "ê°ì§ˆ", "íˆì•Œë£¨ë¡ ì‚°", "ìˆ˜ë¶„"],
            "TROUBLE": ["ì§€ì„±", "ì—¬ë“œë¦„", "íŠ¸ëŸ¬ë¸”", "í”¼ì§€", "í‹°íŠ¸ë¦¬", "ì‹œì¹´", "ì§„ì •"],
            "PORE": ["ëª¨ê³µ", "ë¸”ë™í—¤ë“œ", "ë‚˜ë¹„ì¡´", "ìš”ì² "],
            "AGING": ["ì£¼ë¦„", "íƒ„ë ¥", "ë…¸í™”", "ë ˆí‹°ë†€", "ì½œë¼ê²", "ë¦¬í”„íŒ…"],
            "BRIGHTENING": ["ë¯¸ë°±", "ê¸°ë¯¸", "ì¡í‹°", "ì¹™ì¹™í•¨", "ë¹„íƒ€ë¯¼C", "í†¤ì—…"]
        }
        
        # 1. API í‚¤ ê°€ì ¸ì˜¤ê¸°
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("âŒ .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        self.client = openai.OpenAI(api_key=api_key)

        # 2. [ìˆ˜ì • ì™„ë£Œ] ëª¨ë¸ ì´ë¦„ ì„¤ì • (ê¸°ë³¸ê°’: gpt-5-mini)
        # ì‚¬ìš©ìë‹˜ ìš”ì²­ì— ë”°ë¼ ìµœì‹  ëª¨ë¸ì¸ 'gpt-5-mini'ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
        # ë§Œì•½ APIìƒì˜ ì •í™•í•œ ëª…ì¹­ì´ 'gpt5-mini'ë¼ë©´ .env íŒŒì¼ì—ì„œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.
        self.target_model = os.getenv("OPENAI_MODEL", "gpt-5-mini")

    async def analyze(self, persona: PersonaInput) -> CategoryResult:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„: ë£° ë² ì´ìŠ¤ ì ìˆ˜ ì‚°ì • -> LLM ìµœì¢… íŒë‹¨
        """
        # 1. ë£° ë² ì´ìŠ¤: í›„ë³´êµ° ì••ì¶•
        candidates = self._calculate_rule_base_scores(persona)
        top_candidate_str = ", ".join([f"{c[0]}({c[1]}ì )" for c in candidates[:2]])

        # 2. LLM ì—ì´ì „íŠ¸: ìµœì¢… íŒë‹¨
        final_result = await self._ask_llm_agent(persona, top_candidate_str)
        return final_result

    def _calculate_rule_base_scores(self, persona: PersonaInput) -> List[Tuple[str, int]]:
        scores = {cat: 0 for cat in self.CATEGORY_MAP.keys()}
        
        # ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ í†µí•© (None ê°’ ì œì™¸ ì²˜ë¦¬)
        user_keywords = [
            persona.skinType, 
            persona.sensitivityLevel
        ] + persona.skinConcerns + persona.preferredIngredients
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë§¤ì¹­ í™•ì¸
        for cat, keywords in self.CATEGORY_MAP.items():
            for k in keywords:
                count = sum(1 for data in user_keywords if data and k in str(data))
                scores[cat] += count

        return sorted(scores.items(), key=lambda x: x[1], reverse=True)

    async def _ask_llm_agent(self, persona: PersonaInput, candidates_hint: str) -> CategoryResult:
        prompt = f"""
        ë‹¹ì‹ ì€ ìŠ¤í‚¨ì¼€ì–´ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì •ë³´ë¥¼ ë¶„ì„í•´ ê°€ì¥ ì í•©í•œ 'ë‹¨ í•˜ë‚˜ì˜ ìƒí’ˆ ì¹´í…Œê³ ë¦¬'ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.

        [ë¶„ì„ ì˜ˆì‹œ (Few-Shot)]
        Case 1:
        - ì…ë ¥: 30ëŒ€ ì—¬ì„±, ê±´ì„±, ê³ ë¯¼(ì£¼ë¦„, ì†ê±´ì¡°), ë ˆí‹°ë†€ ì„ í˜¸
        - ë£° ë² ì´ìŠ¤ íŒíŠ¸: AGING(4ì ), MOISTURE(3ì )
        - ê²°ê³¼: {{ "primary_category": "AGING", "reasoning": "ì†ê±´ì¡°ì™€ í•¨ê»˜ ì£¼ë¦„ ê³ ë¯¼ì´ ê¹Šì–´ì§€ëŠ” ì‹œê¸°ë¡œ, ì´ˆê¸° ì•ˆí‹°ì—ì´ì§• ê´€ë¦¬ê°€ ê°€ì¥ ì‹œê¸‰í•©ë‹ˆë‹¤." }}

        Case 2:
        - ì…ë ¥: 20ëŒ€ ë‚¨ì„±, ì§€ì„±, ê³ ë¯¼(ì—¬ë“œë¦„, ê°œê¸°ë¦„), í‹°íŠ¸ë¦¬ ì„ í˜¸
        - ë£° ë² ì´ìŠ¤ íŒíŠ¸: TROUBLE(5ì ), PORE(2ì )
        - ê²°ê³¼: {{ "primary_category": "TROUBLE", "reasoning": "ê³¼ë‹¤ í”¼ì§€ë¡œ ì¸í•œ íŠ¸ëŸ¬ë¸” ë°œìƒ ë¹ˆë„ê°€ ë†’ì•„ ì§„ì • ì¼€ì–´ê°€ 1ìˆœìœ„ì…ë‹ˆë‹¤." }}

        [ì‹¤ì œ ì‚¬ìš©ì ë¶„ì„ ìš”ì²­]
        - ë‚˜ì´/ì„±ë³„: {persona.age}, {persona.gender}
        - í”¼ë¶€íƒ€ì…: {persona.skinType}
        - ê³ ë¯¼: {', '.join(persona.skinConcerns)}
        - íŠ¹ì§•: ì§ì—…({persona.occupation}), ë¯¼ê°ë„({persona.sensitivityLevel}), ìˆ˜ë¶„ë„({persona.moistureLevel}%)
        - ë£° ë² ì´ìŠ¤ íŒíŠ¸: {candidates_hint}
        - ê°€ëŠ¥ ì¹´í…Œê³ ë¦¬: {', '.join(self.CATEGORY_MAP.keys())}

        ìœ„ ì‚¬ìš©ìì— ë§ëŠ” ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
        """

        try:
            response = self.client.chat.completions.create(
                model=self.target_model,  # ğŸ‘ˆ gpt-5-miniê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
                messages=[
                    {"role": "system", "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            
            result_json = json.loads(response.choices[0].message.content)
            
            return CategoryResult(
                primary_category=result_json.get("primary_category", "MOISTURE"),
                reasoning=result_json.get("reasoning", "í”¼ë¶€ íƒ€ì… ë§ì¶¤ ì¶”ì²œ"),
                confidence_score=0.95
            )
        except Exception as e:
            print(f"LLM Error: {e}")
            fallback = candidates_hint.split("(")[0].strip() if candidates_hint else "MOISTURE"
            return CategoryResult(primary_category=fallback, reasoning="ë°ì´í„° ê¸°ë°˜ ìë™ ì¶”ì²œ (AI ì‘ë‹µ ì§€ì—°)", confidence_score=0.7)